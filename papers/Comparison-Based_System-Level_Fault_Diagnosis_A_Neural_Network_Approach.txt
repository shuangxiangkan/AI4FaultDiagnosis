Comparison-Based System-Level Fault Diagnosis: A Neural Network Approach Mourad Elhadef and Amiya Nayak Abstract—We consider the fault identification problem, also known as the system-level self-diagnosis, in multiprocessor and multicomputer systems using the comparison approach. In this diagnosis model, a set of tasks is assigned to pairs of nodes and their outcomes are compared by neighboring nodes. Given that comparisons are performed by the nodes themselves, faulty nodes can incorrectly claim that fault-free nodes are faulty or that faulty ones are fault-free. The collections of all agreements and disagreements, i.e., the comparison outcomes, among the nodes are used to identify the set of permanently faulty nodes. Since the introduction of the comparison model, significant progress has been made in both theory and practice associated with the original model and its offshoots. Nevertheless, the problem of efficiently identifying the set of faulty nodes when not all the comparison outcomes are available to the diagnosis algorithm at the beginning of the diagnosis phase, i.e., partial syndromes, remains an outstanding research issue. In this paper, we introduce a novel diagnosis approach using neural networks to solve this fault identification problem using partial syndromes. Results from a thorough simulation study demonstrate the effectiveness of the neural-network-based self-diagnosis algorithm for randomly generated diagnosable systems of different sizes and under various fault scenarios. We have then conducted extensive simulations using partial syndromes and nondiagnosable systems. Simulations showed that the neural-network-based diagnosis approach provided good results making it a viable addition or alternative to existing diagnosis algorithms. Index Terms—Fault tolerance, system-level self-diagnosis, comparison models, partial syndromes, neural networks. Ç 1INTRODUCTION recent decades, the need for dependable computing [7] and the Chwa-Hakimi comparison model [8], assumeIN systems for critical applications has motivated researchers that a set of jobs is assigned to pairs of distinct units, and the to investigate self-diagnosable large-scale distributed sys-results are compared. The outcomes of these comparisons, tems and loosely coupled multiprocessor and multicompu-i.e., the matching and mismatching results, are used as a ter systems. These so-called loosely coupled multiprocessor basis in order to identify the set of faulty nodes. Fault systems are sometimes composed of hundreds (or even diagnosis under the testing and comparison models thousands) of interconnected processing nodes. In order to assumes in general a worst case behavior. That is, only t-diagnosable systems where the maximum number of faultsdetect faults each node is assumed to test and to be tested by is bounded by tare considered in order to guarantee aother nodes of the system. From the results of the tests, nodes certain level of diagnosis. Finally, probabilistic models [2] doneed to be diagnosed as faulty or fault-free. This problem is not assume any bound, but instead, only fault sets that have known as the system-level fault diagnosis problem. The system-a nonnegligible probability of occurrence are considered.level diagnosis problem has been extensively studied in the In this paper, we consider the comparison-based diag.last three decades (the reader is referred to the following nosis approach. The comparison approach has been intro-surveys [1], [2], and the most recent comprehensive one by duced independently by Malek [7] and by Chwa andDuarte Jr. et al. [3] for more details). Hakimi [8] giving rise to two models. The Malek’s model isThree types of diagnosis models have been studied in the known as the asymmetric comparison model and that ofcontext of system-level self-diagnosis: testing, comparison, Chwa and Hakimi is called the symmetric comparison model.and probabilistic models. Testing models,suchasthe In both models it is assumed that two fault-free nodes giveclassical PMC model [4], and its variations such as the matching (0) results while a faulty and a fault-free nodeBGM model [5] and the HK models [6], assume that each give mismatching (1) outcomes. The two models differ innode is assigned a subset of the other units to test and the the assumption on tests involving a pair of faulty nodes. Indiagnosis is based on the collection of test outcomes. While, the symmetric model, both test outcomes (0=1) are possiblecomparison models, such as the Malek’s comparison model in this case, while in the asymmetric model two faulty nodes always give mismatching outputs (1). . M. Elhadef is with the College of Engineering and Computer Science, Abu In [9], Maeng and Malek extended the comparison model Dhabi University, PO Box 59911, Abu Dhabi, UAE. by allowing the comparisons to be conducted by the nodes E-mail: elhadef@site.uottawa.ca. themselves. Their extended model is known as the Meang/. A. Nayak is with the School of Electrical Engineering and Computer Science, University of Ottawa, 800 King Edward Avenue, Ottawa, Ontario Malek (MM) model. Furthermore, in [9], it was assumed that K1N 6N5, Canada. E-mail: anayak@site.uottawa.ca. a comparison is performed by each node for each pair of Manuscript received 5 Jan. 2011; revised 15 June 2011; accepted 16 Sept. distinct neighbors with which it can communicate directly; 2011; published online 30 Sept. 2011. this special case of the MM model is referred to as the MMRecommended for acceptance by P. Santi. model. In [10], Sengupta and Dahbura presented a general-For information on obtaining reprints of this article, please send e-mail to: ization of the testing and comparison models by introdu.tpds@computer.org, and reference IEEECS Log Number TPDS-2011-01-0013. Digital Object Identifier no. 10.1109/TPDS.2011.248. cing a new model, known as the generalized comparison model Authorized licensed use limited to: University of New South Wales. Downloaded on March 24,2024 at 10:50:14 UTC from IEEE Xplore. Restrictions apply. 1045-9219/12/$31.00  2012 IEEE Published by the IEEE Computer Society Fig. 1. GCM’s invalidation rules. The value besides the undirected edge denotes the comparison outcome. (GCM), in which the comparator node can be one of the two nodes under comparison. Fig. 1 depicts the GCM’s invalidation rules. Blough and Brown introduced next in [11] a combination of a distributed diagnosis and the generalized comparison model in systems having weak reliable broadcast capacity. They developed the first broad.cast comparison model (BCM), in which two nodes under comparison broadcast their outputs to all nodes in the system. In [12], Chessa and Santi applied the comparison-based system-level fault diagnosis approach to ad hoc networks. More recently, Albini et al. [13] introduced the generalized distributed comparison-based (GDC) model which is based on the same assumptions of the MM model, plus, it requires that fault-free nodes execute tasks within a bounded time. Identifying the complete and correct set of faulty nodes using a comparison model has been shown to be NP-hard [14], but if the system is t-diagnosable, the problem is solvable in polynomial time. This problem has been extensively studied leading to elegant and efficient solu.tions [8], [9], [10], [11], [12], [13], [14], [15], [22], [23], [24], [25], [27], [28], [29], [30], [31], [32], [34], [37]. In this paper, we present a totally different approach based on artificial neural networks (ANNs) for solving the system-level diagnosis problem. We consider different comparison models including the Chwa and Hakimi’s symmetric comparison model [8] and the generalized comparison model [10]. Note that the GCM is a general class of the testing models, and hence, the new ANNs-based diagnosis approach could be easily applied to these models as well with minor adaptations. ANNs have been successfully applied to a broad spectrum of applications including medical [16], industrial [17], financial [18], data mining [19], etc. In particular, ANNs have been also used to solve various fault diagnosis problems [20], [21], but to the best of our knowledge, this is the first time where ANNs are used to solve the system-level fault diagnosis. The neural network diagnosis approach is one of the few diagnosis algorithms [10], [22], [23], [24] that have been devised for the GCM-based fault identification problem. We believe that this new type of diagnosis approach could be important in the design of future generations of dependable systems. One of the main contributions of the new diagnosis approach compared to existing deterministic polynomial time diagnosis algorithms is the fact that it can provide a certain level of correct diagnosis even when not all the comparison outcomes are available to the diagnosis algo.rithm at the beginning of the diagnosis phase, i.e., partial syndromes. In addition, the neural-network-based diagno.sis exploits the offline learning phase of neural networks to speed up the diagnosis algorithm providing, hence, online diagnosis. It must be noted that a shorter paper describing an initial version of the neural-network-based diagnosis to the symmetric comparison model was published in [25]. The main difference between the two papers is the addition in this paper of the generalization of the neural network approach to GCM and the new interpolation phase, and inclusion of a more comprehensive set of simulation results. The interpolation process aims at speeding up the diagnosis algorithm by allowing the computation of results from precomputed values. The remainder of this paper is organized as follow: we first provide a general view of the fault and comparison models, followed by basic definitions and notations in Section 2. Section 3 discusses related work. The neural-network-based diagnosis approach is detailed in Section 4, followed by the main steps for improving the diagnosis correctness, i.e., a postprocessing phase and an interpola.tion phase. A concrete example is also provided in Section 4 to help understand the interpolation process. Simulation results are provided in Section 5. Section 6 concludes the discussion and motivates future investigations on the system-level fault diagnosis problem. 2PRELIMINARY DEFINITIONS The system we consider is composed of stable nodes that are interconnected with each other via a wired or wireless communication network. In comparison models, the system is modeled by an undirected graph, and it is assumed that pairs of nodes are assigned the same task to be performed. The agreements (0) and disagreements (1) among the nodes are the basis for identifying the set of faulty nodes. It is assumed that two fault-free nodes always give matching results, while a faulty and a fault-free unit always give mismatching outcomes. The comparison model for system-level fault self-diagnosis can be described by two graphs: a communication graph and a comparison (or test) graph. The communication graph G.V;E.is assumed to be undirected, and represents the interconnection topology of the system (see examples in Fig. 2a and Fig. 3a); an undirected edge e..u;v.represents a communication link between the two nodes uand v. Whereas, the comparison graph shows the comparison tests that are performed in order to identify the set of faulty nodes once a fault situation is detected, i.e., when the system deviates from its expected behavior due to faults in the nodes. Examples of comparison graphs are provided in Fig. 2b and Fig. 3b. The set of all comparison outcomes is called the syndrome, and it is denoted by . The set of all faulty nodes in the system, denoted by F, is called the fault set. We will refer to any comparison syndrome that can be generated under Fand a given comparison model Fig. 2. A three-diagnosable SCM-based system. (a) Communication graph. (b) A comparison assignment and a symmetric comparison syndrome. by F. The objective of the fault identification algorithm is to identify Fgiven F. In this work, we consider only the static permanent faults [26], i.e., software or hardware faults that always produce errors when they are fully exercised. However, we consider both hard and soft faults [12]. A hard-faulted node is unable to communicate with the rest of the system, whereas a soft-faulted node can continue to operate and communicate with the other nodes with altered behavior. Definition 1. A system is t-diagnosable if each node can be correctly identified as fault-free or faulty based on a valid collection of comparison results, assuming that the number of faulty nodes does not exceed a bound t. The fault diagnosis process is based on the comparison syndrome output by the system’s nodes. For a diagnosis to be possible, the behavior of soft faulty nodes should be constrained (or invalidated). Various comparison invalida.tion rules have been defined leading to different comparison models. The main difference between the comparison models is the assumption on the comparisons involving a pair of faulty nodes, once the comparator node is nonfaulty. Two types of comparison models have been studied in the literature: symmetric and asymmetric comparisons (see Fig. 1). In the symmetric model, both comparison outcomes are possible in this case (0 or 1), while in the asymmetric model two faulty compared nodes always give mismatching out.puts, and hence, the comparison outcome is 1. In this paper, we consider two of these comparison models—the Chwa-Hakimi comparison model developed in [8] and the generalized comparison model introduced by Sengupta and Dahbura [10]. The main difference between these two models is that in GCM the comparator node can be one of the nodes being compared. Whereas, in the Chwa-Hakimi model all comparisons are performed by a central observer that monitors the system. However, in both models the diagnosis of faults using the comparison outcomes is performed by the central observer. In the following, a complete description of these two comparison models is provided. 2.1 Chwa-Hakimi Comparison Model In the comparison model developed by Chwa and Hakimi [8], it is assumed that a central observer (comparator) is responsible of performing the comparisons between pairs of nodes by assigning them some tasks from the set of tasks T.fT1;T2;...g. Each pair of nodes viand vjis assigned a task Tl2T. Once the task Tlis completed by both nodes, their results are compared. The comparison graph in this case, is an undirected graph G..V;C., where Vdenotes the set of nodes and C.f.vi;vj.:.vi;vj.is a pair of nodes performing the same task Tl2Tg. We will denote a node pair .vi;vj.or .vj;vi.by cij. The result of the comparison test between the nodes viand vj, a binary value, is associated with cij. This comparison result is 0 if the results generated by both nodes are identical; and it is 1, otherwise, i.e., if their results mismatch. From now on, we will refer to the Chwa-Hakimi model by the simple comparison model (SCM) since it is a special case of the GCM. The SCM is a symmetric comparison model, that is, the outcome of a comparison test involving a pair of faulty nodes is unreliable (0 or 1). Both test outcomes are possible in this model, while in the asymmetric comparison model (the Malek’s model [7]) two faulty nodes always give mismatching outputs. The notation used for the SCM is as follows: .  i: denotes the set of nodes with which a node viis  .  compared, and is given by i.fvj:cij2Cg. ij: refers to the outcome of the comparison cijin the  syndrome  ,  i.e.,  the  outcome  of  the  comparison  conducted between viand vj.  .  .vi.:  defines the  set  of results of the comparison  tests that are carried out between the node viand all  its neighbors, and is given by  vj;ij.:vj2.vi..f. i&cij2Cg.  Definition 2. A comparison syndrome is said to be consistent (or compatible) with a fault set FVunder SCM if for any ij2, such that vi2VF, ij.1iff vj2F. Definition 3. A comparison assignment graph G.V;C.under SCM is a D.jVj.design iff for all vi2V;jij, i.e., each node is at least compared with other nodes. Systems belonging to this special design D.jVj.have been shown to be t-diagnosable in [27] and they can be easily generated. A small system connecting seven nodes is shown in Fig. 2a. A typical comparison assignment is provided in Fig. 2b, and a symmetric comparison syndrome correspond.ing to the actual fault set F.fv5;v7gis also given. Note that 5;7.0according to the symmetric invalidation rules. This example is a SCM-based three-diagnosable system [27]. 2.2 Generalized Comparison Model Maeng and Malek extended in [9] the SCM by allowing the comparisons to be conducted by the nodes themselves for each pair of neighbors with which they can communicate directly. We will refer to their model as the MM* model. A more elegant generalization of testing [4], [5], [6] and comparison models [7], [8], known as the generalized comparison model, has been introduced next in [10] by Sengupta and Dahbura, in which the comparator can be one of the two nodes under comparison. Recall that under the testing models nodes test each other directly, i.e., the comparator can be one of the nodes under comparison. According to GCM, if the comparator node is fault-free, then the comparison outcome is 0 if none of the compared nodes is faulty, and it is 1 if one of them is faulty. However, if the comparator itself is faulty, then the comparison outcome is unreliable, and hence, may be 0 or 1 (see Fig. 1). In this model, the comparison graph is a multigraph whose edges represent comparison tests performed by the system’s nodes themselves. Each node is assigned a subset of the other nodes to test. Testing is based on assigning a set of tasks T.fT1;T2;...gto the system’s nodes, and comparing their outcomes. A pair of nodes .vi;vj.(or .vj;vi.) is assigned a task Tl2T. Once the task Tlis executed by both processing nodes, the results are compared. We represent the comparison multigraph by an undirected graph M.V;C.,where Vand Cdenote, respectively, the vertices (nodes) and the edges (comparison tests). For every vi;vj;vk2V, .vi;vj;vk.2C,orsimply cijk2C, iff node vktests nodes viand vjby assigning them the same task. Each edge cijkhas a label associated with it. The binary value assigned to the label depends on the GCM’s invalidation rules as shown in Fig. 1. Fig. 3a shows an example of a five-nodes interconnection graph, and Fig. 3b, adopted from [10], depicts an example of a GCM-based comparison multigraph. In the following, we generalize SCM’s notations to GCM. Let vi;vj;vk2Vbe any nodes in V. The subscript kwill be used to designate a comparator node. . cijk: denotes a comparison test performed by node vkbetween nodes viand vj, cijk2C. . i: denotes to the set of nodes (neighbors) to which viis compared and is defined by i.fvj:9vk2Vsuchthatcijk2Cg. 1. : defines the set of all comparators of node viandi1all its neighbors, and is given by .fvk:9vj2iisuchthatcijk2Cg. .1. : denotes the set of node pairs that are comparedk.1by the node vk, and is defined by .f.vi;vj.:kcijk2Cg. . ijk: refers to the outcome of the comparison test cijkin the syndrome , i.e., the result of the comparison test that is conducted by vkon both nodes viand vj. .1. .vk;.: refers to the subset of the syndromekcontaining only the outcomes of comparison tests .1executed by node vk, and is defined by .vk;..kvi;vj;ijk.:..1f.vi;vj.2kg. . .vi;i.: refers to the subset of syndrome contain.ing only the outcomes of comparisons performed between node viand its neighbors, and is given by .vi;i..f.vj;vk;ijk.:vj2i&vk2i1&cijk2Cg. Definition 4. A syndrome is consistent (or compatible) with the fault set FVunder GCM if for each ijk2such that vk2VF, ijk.1iff vi2Fand/or vj2F, i.e., at least one compared node is faulty. Definition 5. A system with interconnection topology repre.sented by the undirected graph G..V;E.is a ID.jVj.design if for each pair of vertices vi;vj2Vsuch that ji.kmodulojVj, where k.1;2;...;, an undirected edge between viand vjexists. Fig. 4 provides an example of a ID3.12.interconnection topology. Definition 6. A multigraph M..V;C.is a D.jVj.designtif it is produced from a IDt.1.jVj.system topology under the MMmodel. Sengupta and Dhabura showed in [10] that the special design D.jVj.is t-diagnosable. Note that it can be easilytgenerated even when very large systems are considered. Fig. 4. An example of a ID3.12.interconnection topology. 3RELATED WORK Identifying the correct set of all faulty nodes using the comparison approach has been shown to be NP-Hard [14], but if the system is t-diagnosable, the problem is solvable in polynomial time. This problem has been extensively studied leading to various solutions. Nevertheless, the problem of efficiently identifying the set of faulty units when not all the comparison outcomes are available to the diagnosis algorithm at the beginning of the diagnosis phase, i.e., partial syndromes, remains an outstanding research issue. In the following, t, V, and Cdenote the maximum number of faults allowed in a system, the set of nodes, and the set of comparison tests, respectively. For their symmetric comparison model, Chwa and Hakimi developed an O.jCj.diagnosis algorithm [8]. While, for the asymmetric comparison model, various fault diagnosis algorithms have been proposed. In [28], Ammann and Dal Cin proposed a O.jVj2.sequential diagnosis algorithm for a subset of t-diagnosable systems. Evolutionary approaches (genetic algorithms [29], artificial immune systems [30], and swarm intelligence [31]) have been also used to solve the comparison-based fault diagnosis pro.blem. Recently, in [12], Chessa and Santi presented a new comparison-based diagnostic model based on one-to-many communication paradigm which takes advantage of the shared nature of ad hoc networks. They introduced a diagnosis protocol and two implementations of their model considering whether the network topology can change during diagnosis or not. Their work has been improved more recently in [32] using a more adaptable approach. Since the introduction and the characterization of GCM, by Sengupta and Dahbura [10], very little work has been done to tackle the system-level diagnosis problem under GCM. In [10], Sengupta and Dahbura gave necessary and sufficient conditions for GCM-based systems to be t-diagnosable. Moreover, they developed a diagnosis algorithm having a time complexity of O.jVj5., which makes it unpractical specially when considering large systems composed of hundreds or even thousands of nodes. Recently, Yang and Tang [22] developed a more efficient diagnosis algorithm, inspired from the solution provided by Dahbura and Masson in [33], which requires only O.jVj3., where and denote the maximum and minimum degrees of a node, respectively. A parallel evolutionary approach has been proposed by Abrougui and Elhadef [23] to solve the self-diagnosis problem under GCM. The parallel genetic approach has been shown to correctly identify the set of faulty nodes. In [34], Stewart presented a diagnosis algorithm for special systems under the GCM with time complexity O.maxjVj., where maxis the maximal degree of any node of the graph. In [14], Blough and Pelc studied the complexity of fault diagnosis under comparison models and they provided efficient algorithms for diagnosing systems for which the comparison assignment is a bipartite graph. Wang et al. presented in [24] new necessary and sufficient condition for a system to be t-diagnosable under GCM. In addition, they presented a class of systems that uses the minimum number of communication links to obtain a given degree of diagno.sability. An interesting distributed diagnosis algorithm has been also introduced in [24] that aims at reducing the number of tests necessary for diagnosis when the number of faults is relatively small. In [11], Blough and Brown introduced an hybrid model by combining distributed diagnosis and GCM. The Blough and Brown’s model is known as the broadcast comparison model. The originality of the BCM comes from the fact that any two nodes under comparison broadcast their results to all nodes in the system. Once the results are received by all fault-free nodes, they are compared. Based on a sufficient set of comparison outcomes, fault-free nodes can identify the set of faulty ones. The time complexity of the Blough and Brown’s algorithm is estimated as O.jCj.jVjt2.. In [13], the generalized distributed comparison-based model has been introduced. The GDC model assumes, in addition to all the MM model assumptions, that fault-free nodes execute tasks within a bounded time. The GDC model is fully distributed and does not assume a reliable broadcast system primitive. Albini et al. [13] developed a hierarchical compar.ison adaptive distributed diagnosis algorithm, called Hi-Comp, which is .jVj1.-diagnosable and requires log2jVjtesting rounds, with a maximum number of executed tests evaluated to O.jVj3.. Other extensions of the GDC model have been proposed. Readers are refereed to the most recent survey [3] for more details. In [15], Elhadef has shown that a perceptron-based neural network can be used to solve the system-level diagnosis problem under the Malek’s asymmetric comparison model, and that the perceptron-based diagnosis has failed (i.e., correctness less than 100 percent) when the symmetric SCM was considered. In fact, the diagnosis problem under the Malek’s asymmetric comparison model is a separable one given that any fault set produces only one consistent syndrome. That is, any fault set can only be identified by a unique syndrome since all Malek’s invalidation rules are reliable [7]. While, under the symmetric SCM a fault set may generate many consistent syndromes since comparisons involving pairs of faulty nodes are unreliable. Hence, the diagnosis problem under the symmetric SCM is a nonsepar.able one. The present work is an extension of the perceptron.based diagnosis in which a multilayered artificial neural network is used since it is known to be efficient for nonseparable problems. This new diagnosis approach can efficiently identify the set of faulty units when not all the comparison outcomes are available to the diagnosis algo.rithm at the beginning of the diagnosis phase. Hence, it becomes attractive for situations where not all comparison outcomes are available, or takes long period of time to compute all of them especially for large systems. Simulation results have shown that the ANN-based fault identification algorithm is efficient, making it a viable addition to present diagnosis techniques. 4BACKPROPAGATION NEURAL NETWORK (BPNN)-BASED DIAGNOSIS ALGORITHM The key idea of using artificial neural networks for solving the system-level diagnosis problem was inspired by the fact that ANNs have been extensively studied as classification and/or pattern recognition mechanisms. The fault diag.nosis problem under the comparison models can be described as a classification problem which aims at classifying the system’s nodes either as faulty or fault-free. It can also be described as a pattern recognition problem which objective is to organize the raw data (i.e., the input syndromes) into meaningful categories (i.e., their corre.sponding fault sets). In recent years an enormous number of publications on refinements and improvements of various types of neural networks have been published. However most of the suggested improvements are only useful if the problem meets certain conditions [35]. Nevertheless, the multilayer feedforward networks trained with the back-propagation method are probably the most practically used networks for real world applications. In this work, we will mainly focus on backpropagation neural networks which have been extensively studied in the literature, and various surveys, tutorials, and implementa.tions exist [36]. As a matter of fact, in this section, we will not go into too much details on how to implement a BPNN, rather then we will focus on how to adapt BPNNs to the system-level diagnosis problem under comparison models. However, in order to make the paper self-contained, we included below a short description and the main steps of our BPNN-based diagnosis algorithm. 4.1 Diagnosis Algorithm The multilayer neural network that will be used to model the system-level diagnosis problem can be described as follows: W1;b1W2;b2WL;bL01Lx!x!!xwhere Ldenotes the number of layers and x0., that is, the input layer is the set of comparison outcomes. The other layers are of various sizes depending on the size of the systems (see Section 5 for more details). For all l.1;...;L, Wlis an nlnl1weight matrix for layer l. There are L.1layers of neurons, and Llayers of synaptic weights. The first layer is the input layer and the last layer is the output layer. The aim of the BPNN is to change the Lweights Wand biases bso that the actual output xbecomes closer to the desired output d. Fig. 5 describes an example of the neural network that will be created for the comparison multigraph and syndrome included in Fig. 3b. Note from the figure that a comparison outcome affects only the nodes it involves. For example, the comparison outcome 2;3;1.1affects the neuron v1since it is the comparator (showed in dashed line in Fig. 5), and the neurons v2and v3since these are the compared nodes. Note also that we have converted the comparison outcomes as follows: a 0 comparison outcome is converted to 0:5, while a 1 comparison outcome is converted to 0.5. The backpropagation algorithm consists of the following main steps. 0. Step 1: Forward pass. The input vector xis Ltransformed into the output vector x, by evaluating the following equation: 8l.1;...;L ! nl1lll1XWlx.f.f.bl;.1.iiijxjij.1where nldenotes the size of the layer l.The activation function fused for each neuron is the 1sigmoı¨d function: f.x..which has the very1.expxnice property that its derivative is given by f0.x..f.x..1f.x... In other words, the forward pass step updates the output value for each neuron. That is, for each layer l, starting with the first hidden l1layer, it takes the input vector xto each neuron and finds the output by first calculating the weighted sum of inputs and then applying the sigmoı¨d function fto it, and passes it forward to the next layer until the output layer is updated. . Step 2: Error computation. The difference between the Ldesired output dand the actual output xis computed LlL.f0dixiiillL.f1fdix;iiiwhere f0is the derivative of the sigmoı¨d activation function f. . Step 3: Backward pass. The error signal at the output units is propagated backwards through the entire network, by evaluating Fig. 6. Pseudocode for BPNN-based diagnosis. nlXl1.f0l1jj lWl...;L:iij;8l.2; i.1 . Step 4: Learning updates. The synaptic weights and biases are updated using the results of the forward and backward passes, l1Wl.lix;8l.1;...;L;ijjbl.l;8l.1;...;L;iiW.t.1..W.t..W.t..W.t1.;where trefers to the time or to the epoch number. . Step 5: Stopping condition. The above four steps are repeated using a training set of fault situations and their corresponding consistent syndromes until a stopping criterion is satisfied. Possible stopping criteria in error backpropagation learning include: 1) total error of the network falling below some predetermined level, 2) a certain number of epochs having been completed (as shown in our simulation results in Section 5), or 3) combinations of the two (e.g., whichever of the two occurs first). Other stopping conditions are also possible [35]. The learning coefficient determines the size of the weight changes. A small value for will result in a very slow learning process. If the learning coefficient is too large it will result in large weight changes that may cause the desired minimum to be missed. A useful range is between 0.05 and 2 dependent on the problem. An improved technique is to use an adaptive learning rate. A large initial learning coefficient shouldhelptoescapefromlocal minima, while reducing later should prevent the learning process from overshooting the reached minimum. The momentum causes the weight changes to be dependent on more than one input pattern. The change is a linear combination of the current gradient and the previous gradient. The useful range for this parameter is between 0 and 1. For some data sets the momentum makes the training faster, while for others there may be no improvements. The momentum usually makes it less likely that the training process will get stuck in a local minimum. Once the neural network is trained it can be used to diagnose any fault situation that may occur. The pseudo-code for diagnosing a fault set is given in Fig. 6. An important step in our diagnosis algorithm is how to convert the neural network outputs to a fault set. We Fig. 7. Pseudocode for converting the neural network outputs to a fault set under SCM. TABLE 1 Neurons’ Outputs for a D.10.GCM-Based Multigraph4refereed to this in Fig. 6 by calling the procedure ConvertNetworkOutput.xL.. The objective of such proce.dure is to convert the output vector xLinto the set of faulty nodes Fand the set of fault-free ones FF. For SCM, we used a simple mapping function ConvertNetworkOutputSCM, see Fig. 7, that maps any output less than or equal to 0.5 to a faulty state. Given the simplicity of SCM, this conversion provided good results as shown in Section 5. For GCM, we have adopted a different approach. To clearly explain how we extract the set of faulty nodes consider the neurons’ outputs, sorted in a descending order as shown in Table 1, for the comparison multigraph D.10..4Faulty nodes are pointed by /. First note that the BPNN was able to separate between the two classes: the faulty nodes and the fault-free ones. However, from the extensive simulations, we have conducted we have noticed that the boundary between the two classes is not well defined all the time. Hence, we have adopted the following heuristic to be able to extract the set of faulty nodes by using the comparison multigraph Cand the input syndrome F. The heuristic proceeds in the following steps: 1. Set position variable posto the start of the array. 2. Label the node in position posas fault-free and add it to the set PendingFF. In the provided example, the state of node v8will be fault-free, and the set PendingFF.fv8g. Increase value of posby one. 3. Repeat the following steps until all nodes are labeled either as fault-free or as faulty, or pendingFFis empty. a. Consider vk2PendingFFif not empty. For each .1pair of nodes .vi;vj.2,if ijk.0and thekFstate of one of the two compared nodes viand vjis fault-free, then set the state of the unknown node as fault-free and add it to pendingFF; otherwise, set it to faulty if the number of faulty ijknodes did not reach the bound t.If .1andFthe state of one of the two compared nodes is fault-free, then set the state of the unknown node as faulty if the number of faulty nodes did not reach the bound t; otherwise set it to fault-free. b. If pendingFF.;, then goto Step 2. The described heuristic has been implemented and extensively tested as shown in Section 5. In all scenarios, this heuristic has been successful in correctly converting the neurons’ outputs to faulty or faut-free states. 4.2 Avoiding Local Optima In order to avoid local optima a postprocessing phase has been developed. In fact, during the simulations of the new BPNN-based diagnosis algorithm, we have noticed that the neural network sometimes reached local optima; hence, providing us with incorrect results especially when the number of faulty nodes is too high, i.e., reaches the bound t. One of the main reasons could be either lack of training (as we stop the training after a fixed number of training epochs), or it could be the size of the neural network (the number of layers and the number of neurons per layer) as this was determined only based on the number of nodes in the system. In order to correct this deficiency, we developed a postprocessing phase that corrects the solution proposed by the BPNN-based diagnosis. The postprocessing phase takes as input the potential fault set IFoutput by the neural network, and corrects it. In the following, we describe how it works and we formalize it. In this formalization, we will refer only to the GCM, and we will show that it can be easily specialized to the SCM. Let’s consider a fault situation, where Fis the actual fault set and Fdenotes one of its compatible syndromes. Consider a potential fault set IF(output by our BPNN-based diagnosis algorithm) and let IFdenote one of its compatible syndromes. Intuitively if both syndromes Fand IFare identical, then one can easily conclude that F.IF, i.e., IFis the actual fault set, since we are considering only t-diagnosable systems. To check whether syndromes Fand IFare identical, we compute the probability, P,of both fault sets being identical, and is given by P P.v2VIF;F;v.P.IF;F..;.2.jVjwhere P.IF;F;v.denotes the probability of v’s state being correct according to fault set Fand is defined by P.1.IF;F;v..P1.IF;F;v.P.IF;F;v..;.3.2IFv;.1\Fv;.1vvP.1.IF;F;v..;.4..1vjIF.v;v.\F.v;v.jP1.IF;F;v..:.5.jvjNote that the probability of v’s state being correct according to fault set Fis composed of two components: P.1.IF;F;v.and P1.IF;F;v.. P.1.IF;F;v.measures the correctness probability of v’s state as a tester (or comparator) node, and P1.IF;F;v.calculates that as a tested (or compared) node. We assume that for the special case where j.1j.0, i.e., vdoes not perform any compar.visons, P.1.IF;F;v..1. In the SCM, any node vdoes not perform comparisons, .1and hence, the set is empty. It follows that for SCM,vP.1.IF;F;v..1;8v2V, and hence (3) can be reduced to jIF.v.\F.v.jP.IF;F;v..:.6.jvjEquations (4) and (5) state that the individual probabil.ities can be easily computed by checking how many comparison outcomes, in both syndromes Fand IF, corresponding to comparison tests performed between the node vand all its neighbors are identical. Note that j.1jvand jvjare used just as normalization factors. It follows that P.IF;F;v.2.0;1. When P.IF;F;v..1this means that according to node v(local view) both syndromes are identical, and hence, suggests a common origin, i.e., the same fault set. In addition, P.IF;F.2.0;1and can be seen as the degree of resemblance of both syndromes or as the correctness probability of the potential fault set IF. The postprocessing phase consists in calculating P.IF;F..If P.IF;F..1then the fault set is found; Otherwise, the proposed potential solution needs to be corrected as follows. The nodes are ordered, in an ascending order, based on P.IF;F;v.;8v2V. Then, the state of the node with the smallest P.IF;F;v.is changed, i.e., flipped from faulty (1) to fault-free (0) and vice-versa, and the postprocessing phase is repeated. The stopping criteria is either P.IF;F..1, that is the potential fault set IFwas corrected, or the number of changes has exceeded the size of the system, jVj, i.e., the correction failed. In Section 5, we show the efficiency of such postprocessing phase. Computing P.IF;F.could be time consuming espe.cially for large systems. In fact, the time complexity of this step is O.jCj.. In a comparison graph generated from a fully connected interconnection graph using the MM* model, we have jCj.jVj.jVj2..jVj3.comparison tests. Hence, 3O.jCj..O.jVj.. To overcome this, we have developed a method for interpolating P.IF;F.from another precom.puted value of P.;;F.. The interpolation process has reduced the time complexity of the computing P.IF;F.to 2O.tjVj.. In the following, we describe in details how this interpolation works, and we provide a concrete example to help understand this interpolation process. 4.3 Interpolation Process To speedup the postprocessing phase, and hence reduce the time taken to correct a potential solution output by our BPNN-based diagnosis algorithm we have developed an interpolation method whose objective is to compute P.IF;F.from a pre-computed value of P.;;F.. Before we describe in details how it works we need first to introduce simplified versions of (2)-(5) by omitting the normalization factors. This will help in avoiding the problem of rounding-off errors in computations based on small probabilities. The simplified versions are as follows: TABLE 2 TABLE 3 Syndromes for Fault Sets F.fv2g, IF.fv1g, and ;Precomputed and Expected Values X IP.IF;F..IP.IF;F;v.;v2V1.IP.IF;F;v..IP.1.IF;F;v..IPIF;F;v.;IP.1.IF;F;v..jIFv;.1\Fv;.1j;.7.vvIP1.IF;F;v..jIF.v;v.\F.v;v.j:.8.The new versions are based on integer calculations, and hence, the stopping criteria P.IF;F..1turns out to be now IP.IF;F..3jCjsince a comparison test is counted three times: one in (7) as a comparator and twice in (8) one for each compared node. The interpolation method we used takes as inputs the pre.computed values of IP.1.;;F;v.and IP1.;;F;v..To interpolate IP.IF;F.from IP.;;F.we proceed as follows: I1. For each u2VIF, IP.1.IF;F;u..IP.1.;;F;u.;IP1.IF;F;u..IP1.;;F;u.:I2. For each vk2IF, compute IP.1.IF;F;vk.and adjust the values of IP1.IF;F;vi.and IP1.IF;F;vj.for .1ijkijkall .vi;vj.2k, only if 6..IF;I3. For each vi2IF, compute IP1.IF;F;vi.and adjust the values of IP1.IF;F;vj.and IP.1.IF;F;vk.for ijkijkall vj2iand vk2j1, only if 6..IF;The adjustment of the values in Steps I2 and I3 is done by either adding or subtracting one, and it is performed using ijkijkthe following rule: if ., add one; otherwise, subtract FIFone. A concrete example is shown below to help understand the interpolation process. The time complexity of the interpolation process is 2reduced to O.tjVj.. In fact, in the worst case a node can be involved in .n2..n3.comparison tests as a comparator, where n.jVj. Hence, step I2 can be done in O.tn2., since jFj.tin the worst case. On the other hand, a node can be part of .n1..n2.comparison tests as a compared node. It follows that the time complexity of step I3 is also O.tn2., since in the worst case jFj.t. As a result, the time complexity of 2the interpolation process is O.tjVj.. 4.3.1 How Does Interpolation Work? Consider the comparison multigraph of Fig. 3b. The actual fault set is F.fv2g. A consistent syndrome for each of the fault sets F, IF.fv1g, and ;is provided in Table 2 TABLE 4 Interpolation Process 4;5;14;5;1a Rule I2: since F.6IF, then subtract one. b Rule I3: since 1;3;21;3;21;5;31;5;36, then subtract one. c Rule I3: since ., then.6FIFFIF1;2;41;2;4subtract one. d Rule I3: since F.IF, then add one. e Rule I3: 1;2;51;2;5since F.IF, then add one. assuming symmetric invalidation rules, where IFis the potential fault set output by the diagnosis algorithm. We will show in details the interpolation of P.IF;F.from P.;;F.. First note that P.;;F.is already precomputed, that is, for each vi2V, IP.1.;;F;vi.and IP1.;;F;vi.are known as shown in Table 3A. The objective is to interpolate those of fault set IF. The interpolation rule I1 is straightforward. Let consider rule I2, we compute IP.1.IF;F;v1.following (7), and at the same time we will adjust only IP1.IF;F;v4.and IP1.IF;F;v5.as 4;5;14;5;14;5;14;5;1we have 6.. Since 6., the adjustmentIF;IFFis done by subtracting one. Finally, we consider the interpolation Rule I3. We compute IP1.IF;F;v1.using (8), and simultaneously we adjust IP1.IF;F;vj.and IP.1.IF;F;vk.for all vj21.1jk1jk1jkfv2;v3;v5gand vk2j1, only if IF6.;. Note that IF6.1jk1;3;21;3;2;8j;k(pointed by in Table 2). Since 6.,it ;FIFfollows that the adjustment is by subtracting one from 1;5;3IP1.IF;F;v3.and IP.1.. Similarly, since 6.IF;F;v2.F1;5;3we subtract one from IP1.IF;F;v5.and from IFIP.1.IF;F;v3.. 1;2;41;2;4Now, since ., it follows that the adjustment isFIFby adding one to IP1.IF;F;v2.and IP.1.IF;F;v4.. Similarly, we perform the same adjustment when consider.1;2;5ing . As result, we get the values IP.1.IF;F;vi.andIFIP1.IF;F;vi.shown in Table 4. Note that they are identical to the ones we were expecting (see Table 3B). 5SIMULATION RESULTS We have developed two versions of the new diagnosis algorithm—one for the simple comparison model and the other for the generalized comparison model. Randomly generated t-diagnosable and nondiagnosable comparison graphs have been used for the experiments. To make the generation of the various comparison graphs easy, we used t-diagnosable comparison graphs from the special designs, D.jVj.and D.jVj., introduced in Definitions 3 and 6. Wethave also experimented the BPNN-based diagnosis algo.rithm with partial syndromes, i.e., when not all the comparison outcomes are available to the diagnosis algo.rithm at the beginning of the diagnosis phase. The BPNN-based diagnosis algorithm relies mainly on five parameters, which are: the number of hidden layers numLayers, the number of neurons per layer, the momentum , the learning rate , and the number of epochs maxEpochs. The momentum is set to 0.5 for GCM, and to 0.1 for SCM. The learning rate was fixed to 0.5 and gradually decreased at the end of the learning phase depending on the number of epochs. Let n.jVj. The number of hidden layers was set as follows: if n50, numLayers.3,elseif n100, numLayers.4, else numLayers.5. Each hidden layer is composed of n.log.nmod10.nneurons (if nmod10.0, then we have chosen n.log.n.n.n). In Appendix A, which 10can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TPDS.2011. 248, we have included the description and the results of the experiments, we have conducted to find these settings. To clearly show that the BPNN-based fault diagnosis algorithm works efficiently, and to check its practical performance, we have conducted various extensive experi.ments using both diagnosable and nondiagnosable systems. We have first showed that the BPNN-based diagnosis works correctly for t-diagnosable systems. Then, we have considered nondiagnosable systems, and we have showed that the new diagnosis approach provided good results even though not all the comparison outcomes were available to the diagnosis algorithm at the beginning of the diagnosis phase. In the following, we describe the results of the various experiments we have conducted. 5.1 Performance Using t-Diagnosable Systems The BPNN-based fault diagnosis algorithm has been implemented in C++, and it has been extensively simulated on a PC equipped with an Intel Core 2 QUAD Q8300 CPU 2.5 GHz and 4 GB of RAM. Randomly generated t-diagnosable comparison graphs have been used for the experiments. In addition, all possible fault sets that may occur in a t-diagnosable system have been simulated, when it is possible, by varying the number of faults from 1 to t. However, a more practical approach would be by generat.ing fault sets according to the reliability and the probability of failure of the nodes. But, we have decided to generate the faults randomly in order to be able to test the performance of our fault identification algorithm even when fault sets with very low probability of occurring are considered. 5.1.1 Performance under SCM In order to check the performance of the new diagnosis algorithm under SCM, we have run various types of simulations. In the first set of experiments, we considered a D9.20.symmetric SCM-based comparison graph. We have created a BPNN that was extensively trained during 10,000 epochs. We have then tested it using all possible fault sets of cardinality ranging from 1 to 9. For each fault set with cardinality c, 1000crandomly generated syndromes have been tested. In all these tested fault situations the BPNN-based diagnosis was able to identify the correspond.ing faulty nodes. That is, 100 percent correctness. In the second set of simulations, we have considered a large symmetric SCM-based graph D24.100..Wehave created and trained a BPNN for this large system, and then we have tested it using 100,000 randomly generated fault sets of cardinality in the range .1::24. All fault situations have been correctly identified by the diagnosis algorithm, resulting hence in a 100 percent correctness. In another set of experiments, we have run the diagnosis algorithm for various symmetric SCM-based comparison graphs ranging from small systems composed of tens of nodes to large systems composed of hundreds of nodes. The number of nodes, n, was varied from 10 to 1,000 with different paces as follows. If n2.10::100.the pace is 10. But, if n2.100::1000the considered pace was 100. For each comparison graph, a neural network have been created and trained during 10,000 epochs. Then, we have randomly generated, for each value of n, 100ncomparison graphs and tested them for 1;000ntimes using randomly generated fault sets, and where the maximum number of faults maxFaultswas also random. The size of the randomly generated fault sets was equally distributed in the range from 1 to maxFaults. Over all these extensive simulations, the diagnosis algorithm was able to determine the exact fault sets, providing us hence with almost 100 percent correctness. In fact, the diagnosis algorithm has missed very few fault sets specifically those very large. 5.1.2 Performance under GCM Due to the fact that both characterizations of GCM-based t-diagnosable systems, the one provided by Sengupta and Dahbura [10] and that developed by Wang et al. [24], are rather theoretical and difficult to implement specially for large systems, we have used the special class D.jVj.oftdiagnosable systems [10] provided in Definition 6. Since the BPNN-based diagnosis approach does not rely on the comparison multigraph topology, then it follows that the following results remain valid for general graph structures. The simulations we have conducted can be grouped into three sets of experiments. In the first set of experiments, we considered the GCM-based t-diagnosable systems D.10., D.15., D.20., and469D.25.and all possible combinations of faults. That is, we11have experimented our diagnosis algorithm with all possible fault sets with cardinality ranging from 1 to t. Note that for small systems, we were able to generate allPtCnpossible fault sets which are bounded by i, wherei.1n!n.jVjand Cn.For all fault sets with cardinalityi.ni.!i!. smaller than t, our BPNN-based fault diagnosis algorithm was able to identify all faulty nodes. Fig. 8 depicts the diagnosis correctness. However, for very large fault sets with cardinality approaching the bound tthe diagnosis correctness was around 99.5 percent. Even though, we were expecting a 100 percent correctness, we are not worried about this small degradation in performance as in practice the probability of having such fault situation, that is, almost half of the system’s nodes faulty at the same time, is very low. Such extreme fault situation are rare, if Fig. 8. Diagnosis correctness versus number of faulty nodes using D.10., D.15., D.20., and D.25..46911Fig. 9. Diagnosis performance under systematic faulty scenarios using D.10., D.15., D.20., and D.25..46911not impossible. In addition, we believe that this perfor.mance could be improved by changing our postprocessing phase to handle these special cases where the number of faulty nodes approaches the bound t. This improvement is under investigation. We have conducted a second type of experiments where more systematic faulty scenarios have been considered, i.e., where all faulty nodes respond in the same way. Fig. 9 shows the results when considering that all comparisons conducted by faulty nodes will provide 0s as outcomes, and all outcomes of comparisons conducted between two faulty nodes will provide 1s. We can notice, compared to Fig. 8, that there is a degradation in the diagnosis performance especially when the number of faults is very high (almost t). We believe that this can be improved by a newer version of the postprocessing phase that takes into account the number of 1s in the syndrome to estimate the number of faults, and hence, help in correctly updating the neural network’s outputs. In a third set of experiments, we looked at the scalability of the BPNN-based system-level diagnosis approach. When considering larger diagnosable systems, our diagnosis algo.rithm performed very well even in the worst case scenarios that were generated randomly. All these results confirm one thing, neural networks can be used to solve the system-level fault diagnosis problem, and they can be considered as a viable addition to existing diagnosis solutions. 5.2 Performance Using Partial Syndromes Diagnosing large systems using the comparison approach presents many challenges. To date, all proposed diagnosis algorithms assumed that all comparison outcomes are available prior to initiating the diagnosis phase. This could be time consuming as waiting for all comparison tests to be conducted may take long period of time affecting hence the diagnosis latency. We believe that the diagnosis latency needs to be reduced as much as possible in order to improve the dependability of the system, and hence, provide online diagnosis. The neural-network-based approach could be considered as an online system-level diagnosis such the work presented by Blough and Brown in [11]. Note that Blough and Brown presented a distributed diagnosis approach, while the neural-network-based approach is a centralized one. By exploiting the offline learning phase of neural networks our approach was able to speed up the diagnosis. Moreover, when the system is working correctly the diagnosis algorithm can continue learning how to diagnose new fault situations, and as it learns it improves its efficiency as described in Appendix A, available in the online supplementary material. This constitutes the first main contribution of the BPNN-based diagnosis approach compared to exiting diagnosis algorithms. The second main contribution of the BPNN-based diagnosis approach com.pared to exiting diagnosis algorithms is that it works with partial syndromes. In [11], Blough and Brown have shown that partial syndromes occur in real systems as faults may come up during the execution of the diagnosis algorithm. Hence, the syndrome is incomplete (partial) without reflect.ing the new faults. The new diagnosis approach does not rely fully on the whole syndrome to diagnose a fault situation, and hence, it can provide a certain level of correct diagnosis when exposed to partial syndromes. In the following, we describe the performance results when GCM-based partial syndromes are used. Similar results can be obtained for SCM-based systems. 5.2.1 Case 1: Random Partial Syndromes Fig. 10 shows the results of the first type of experiments where we have randomly omitted comparison outcomes. As one can easily deduce from the figure, the BPNN-based diagnosis algorithm was able to provide a certain level of correct diagnosis even though many comparison outcomes were missing. Of course, we were expecting a degradation in diagnosis correctness, but we believe that the partial diagnosis results provided will be useful in situations where not all comparison outcomes are, or until they become, available. To date, none of the existing diagnosis algorithms can work with partial syndromes. 5.2.2 Case 2: Omitting One Node’s Comparison Outcomes In a second type of experiments, we have selected randomly one node and then randomly omitted comparison outcomes that involved this node either as a comparator or as a compared node. Fig. 11 describes the obtained results. The diagnosis algorithm saw a small degradation in perfor.mance that was expectable. We have also noticed that when the selected node was part of a large number of comparison tests, its impact on the diagnosis correctness is considerable especially for small systems. 5.2.3 Case 3: Omitting One Group of Nodes’ Comparison Outcomes Our third experiment aimed at checking the impact of missing the comparison outcomes of a group of nodes. The experiment consisted in generating partial syndromes by randomly selecting a group of nodes and then randomly omitting a certain percentage of the comparison outcomes that involved them either as comparators or as compared nodes. For example, consider two nodes (20 percent of the number of nodes) randomly selected from a D.10.system.4If 20 percent of the comparison outcomes involving these two nodes are missing then the diagnosis correctness is around 89 percent, and it is almost 96 percent for a D.15.6system. Fig. 12 describes the obtained results. We can notice that the diagnosis algorithm continues providing a certain level of correct diagnosis even when large number of comparison outcomes are missing. 6CONCLUSIONS The backpropagation neural network-based diagnosis approach presented in this paper aims at solving the well-known system-level diagnosis problem using compar.ison models such the simple comparison model and the generalized comparison model, and partial syndromes. The proposed approach exploits the offline learning phase of neural networks to speed up the diagnosis algorithm and uses a postprocessing phase to escape local optima. The results from an extensive simulation study have shown that Fig. 12. Omitting a group of nodes’ comparisons. the efficiency of this novel approach in detecting all fault situations. We have shown also that the neural network approach was able to provide good results when partial syndromes and nondiagnosable systems are considered. Future investigations will be twofold. First, we plan to perform an extensive performance evaluation whose objec.tive is to compare all developed system-level diagnosis algorithms to the neural network approach. Second, we are in the process of applying the BPNN-based diagnosis to other diagnosis models, such as the PMC model [4] and the broadcast comparison model [11]. We also believe that given the features of the neural network diagnosis approach, a natural extension would be to apply this new approach to probabilistic models [2], and to hybrid faults as described by Kozlowski and Krawczyk in [37]. It would be also interesting to experiment and analyze the use of alternative mechanisms, such as Hopfield networks and Support vector machines [38], for solving the system-level diagnosis problem. REFERENCES [1] M. Barborak, M. Malek, and A. Dahbura, “The Consensus Problem in Fault-Tolerant Computing,” ACM Computing Surveys, vol. 25, no. 2, pp. 171-220, June 1993. [2] S. Lee and K. Shin, “Probabilistic Diagnosis of Multiprocessor Systems,” ACM Computing Surveys, vol. 26, no. 1, pp. 121-139, Mar. 1994. [3] E.P. Duarte Jr, R.P. Ziwich, and L.C. Albini, “A Survey of Comparison-Based System-Level Diagnosis,” ACM Computing Surveys, vol. 43, no. 22, Apr. 2011. [4] F. Preparata, G. Metze, and R. Chien, “On the Connection Assignment of Diagnosable Systems,” IEEE Trans. Electronic Computer, vol. EC-16, no. 6, pp. 848-854, Dec. 1967. [5] F. Barsi, F. Grandoni, and P. Maestrini, “A Theory of Diagnosa.bility without Repairs,” IEEE Trans. Computers, vol. C-25, no. 6, pp. 585-593, June 1976. [6] S. Kreutzer and S. Hakimi, “Adaptive Fault Identification in Two New Diagnostic Models,” Proc. 21st Allerton Conf. Comm., Control and Computing, pp. 353-362, 1983. [7] M. Malek, “A Comparison Connection Assignment for Diagnosis of Multiprocessor Systems,” Proc. Seventh Int’l Symp. Computer Architecture, pp. 31-35, 1980. [8] K. Chwa and S. Hakimi, “Schemes for Fault Tolerant Computing: A Comparison of Modularly Redundant and t-Diagnosable Systems,” Information and Control, vol. 49, pp. 212-238, June 1981. [9] J. Maeng and M. Malek, “A Comparison Connection Assignment for Self-Diagnosis of Multiprocessor Systems,” Proc. 11th Int’l Symp. Fault-Tolerant Computing, pp. 173-175, 1981. [10] A. Sengupta and A. Dahbura, “On Self-Diagnosable Multi.processor Systems: Diagnosis by the Comparison Approach,” IEEE Trans. Computers, vol. 41, no. 11, pp. 1386-1395, Nov. 1992. [11] D. Blough and H. Brown, “The Broadcast Comparison Model for On-Line Fault Diagnosis in Multiprocessor Systems: Theory and Implementation,” IEEE Trans. Computers, vol. 48, no. 5, pp. 470.493, May 1999. [12] S. Chessa and P. Santi, “Comparison-Based System-Level Fault Diagnosis in Ad Hoc Networks,” Proc. IEEE 20th Symp. Reliable Distributed Systems, pp. 257-266, 2001. [13] L.C. Albini, E.P. Duarte Jr, and R.P. Ziwich, “A Generalized Model for Distributed Comparison-Based System-Level Diagno.sis,” J. Brazilian Computer Soc., vol. 10, no. 3, pp. 44-56, 2005. [14] D. Blough and A. Pelc, “Complexity of Fault Diagnosis in Comparison Models,” IEEE Trans. Computers, vol. 41, no. 3, pp. 318-324, Mar. 1992. [15] M. Elhadef, “A Perceptron Neural Network for Asymmetric Comparison-Based System-Level Fault Diagnosis,” Proc. Fifth Int’l Conf. Availability, Reliability and Security (ARES ’09), Mar. 2009. [16] A. Hassanien, A. Abraham, J. Peters, G. Schaefer, and C. Henry, “Rough Sets and Near Sets in Medical Imaging: A Review,” IEEE Trans. Information Technology in Biomedicine, vol. 13, no. 6, pp. 955.968, Nov. 2009. [17] M. Meireles, P. Almeida, and M. Simoes, “A Comprehensive Review for Industrial Applicability of Artificial Neural Net.works,” IEEE Trans. Industrial Electronics, vol. 50, no. 3, pp. 585.601, June 2003. [18] A.-P.N. Refenes, A. Burgess, and Y. Bentz, “Neural Networks in Financial Engineering: A Study in Methodology,” IEEE Trans. Neural Networks, vol. 8, no. 6, pp. 1222-1267, Nov. 1997. [19] S. Mitra, S. Pal, and P. Mitra, “Data Mining in Soft Computing Framework: A Survey,” IEEE Trans. Neural Networks, vol. 13, no. 1, pp. 3-14, Jan. 2002. [20] J. Korbicz, J.M. Koscielny, Z. Kowalczuk, and W. Cholewa, Fault Diagnosis: Models, Artificial Intelligence, Applications. Springer, 2004. [21] J. He, Z. Zhou, X. Yin, and S. Chen, “Using Neural Networks for Fault Diagnosis,” Proc. IEEE-INNS-ENNS Int’l Joint Conf. Neural Networks (IJCNN ’00), Oct. 2000. [22] X. Yang and Y.Y. Tang, “Efficient Fault Identification of Diagnosable Systems under the Comparison Model,” IEEE Trans. Computers, vol. 56, no. 12, pp. 1612-1618, Dec. 2007. [23] K. Abrougui and M. Elhadef, “Parallel Self-Diagnosis of Large Multiprocessor Systems under the Generalized Comparison Model,” Proc. 11th Int’l Conf. Parallel and Distributed Systems, pp. 78-84, July 2005. [24] H. Wang, D. Blough, and L. Alkalaj, “Analysis and Experimental Evaluation of Comparison-Based System-Level Diagnosis of Multiprocessor Systems,” Proc. 24th Int’l Symp. Fault-Tolerant Computing, pp. 55-64, 1994. [25] M. Elhadef and A. Nayak, “Efficient Symmetric Comparison-Based Self-Diagnosis Using Backpropagation Artificial Neural Networks,” Proc. IEEE 28th Int’l Performance Computing and Comm. Conf. (IPCCC ’10), pp. 264-271, Dec. 2010. [26] A. Avizienis, J.-C. Laprie, B. Randell, and C. Landwehr, “Basic Concepts and Taxonomy of Dependable and Secure Computing,” IEEE Trans. Dependable Secure Computing, vol. 1, no. 1, pp. 11-33, Jan.-Mar. 2004. [27] A. Pelc, “Undirected Graph Models for System Level Fault Diagnosis,” IEEE Trans. Computers, vol. 40, no. 11, pp. 1271-1276, Nov. 1991. [28] E. Ammann and M. DalCin, “Efficient Algorithms for Compar.ison-Based Self-Diagnosis,” Proc. Self-Diagnosis and Fault-Tolerance, pp. 1-18, 1981. [29] M. Elhadef and B. Ayeb, “Efficient Comparison-Based Fault Diagnosis of Multiprocessor Systems Using an Evolutionary Approach,” Proc. 15th Int’l Parallel and Distributed Processing Symp. (IPDPS ’01), Apr. 2001. [30] M. Elhadef, S. Das, and A. Nayak, “System-Level Fault Diagnosis Using Comparison Models: An Artificial-Immune-Systems-Based Approach,” J. Networks, vol. 1, no. 5, pp. 43-53, Nov. 2007. [31] M. Elhadef, A. Nayak, and N. Zeng, “An Ant-Based Fault Identification Algorithm for Distributed and Parallel Systems,” Proc. 10th World Conf. Integrated Design and Process Technology Conf. (IDPT ’07), June 2007. [32] M. Elhadef, A. Boukerche, and H. Elkadiki, “A Distributed Fault Identification Protocol for Mobile Ad-Hoc and Wireless Mesh Networks,” J. Parallel and Distributed Computing, vol. 68, no. 3, pp. 321-335, Mar. 2008. 2:5.[33] A. Dahbura and G. Masson, “An O.nFault Identification Algorithm for Diagnosable Systems,” IEEE Trans. Computer, vol. C-33, no. 6, pp. 486-492, June 1984. [34] I. Stewart, “A General Algorithm for Detecting Faults Under the Comparison Diagnosis Model,” Proc. 24th Int’l Parallel and Distributed Processing Symp. (IPDPS ’10), pp. 19-23, Apr. 2010. [35] D.W. Patterson, Artificial Neural Networks: Theory and Applications. Prentice Hall, 1996. [36] “Neural Network Warehouse: AI Depot,” http://neuralnetworks. ai-depot.com/, 2011. [37] W.E. Kozlowski and H. Krawczyk, “A Comparison-Based Approach to Multicomputer System Diagnosis in Hybrid Fault Situations,” IEEE Trans. Computers, vol. 40, no. 11, pp. 1283-1287, Nov. 1991. [38] J. Shawe-Taylor and N. Cristianini, An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods. Cam.bridge Univ. Press, 2000. Mourad Elhadef received the BSc and MSc degrees in computer science from the Institut Supe´rieur de Gestion, Tunis, Tunisia, and the PhD degree in computer science from the university of Sherbrooke, Que´bec, Canada. Currently, he is working as an associate professor at the College of Engineering and Computer Science, Abu Dhabi University. Prior to this, he held a faculty position at the University of Ottawa, Ontario, Canada. His research interests include fault tolerance and fault diagnosis in distributed, wireless and ad hoc networks, fault tolerance of optical networks, artificial intelligence, swarm intelligence, artificial immune systems, and genetic algorithms. Amiya Nayak received the BMath degree in computer science and combinatorics and opti.mization from the University of Waterloo, in 1981 and the PhD in systems and computer engineer.ing from Carleton University, in 1991. He has more than 17 years of industrial experience in software engineering, avionics and navigation systems, simulation and system-level perfor.mance analysis. He is in the editorial board of several journals, including IEEE Transactions on Parallel and Distributed Systems, International Journal of Parallel, Emergent and Distributed Systems, International Journal of Computers and Applications, and EURASIP Journal of Wireless Communications and Networking. Currently, he is working as a full professor at the School of Electrical Engineering and Computer Science at the University of Ottawa. His research interests include the area of fault tolerance, distributed systems/algorithms, and mobile ad hoc networks with more than 150 publications in refereed journals and conference proceedings. .For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib. 